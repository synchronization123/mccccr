import requests
import pandas as pd

# API details
API_URL = "https://dependencytrackapi.crm.com/api/v1/project"
API_TOKEN = "bzbdbdhdhd"
HEADERS = {
    "X-Api-Key": API_TOKEN,
    "Content-Type": "application/json",
    "Accept": "application/json"
}

def fetch_all_dependency_data():
    """Fetch all pages of Dependency Track API data."""
    all_data = []
    page = 1
    limit = 100  # Set the limit per request

    while True:
        params = {"page": page, "limit": limit}  # Add pagination parameters
        try:
            response = requests.get(API_URL, headers=HEADERS, params=params)
            response.raise_for_status()
            data = response.json()

            if not data:
                break  # Stop if no more records
            
            all_data.extend(data)  # Append current batch to full list

            print(f"Fetched {len(data)} records from page {page}")
            
            # Stop if fewer than 'limit' records are returned (last page reached)
            if len(data) < limit:
                break

            page += 1  # Move to the next page
        except requests.exceptions.RequestException as e:
            print(f"Error fetching data: {e}")
            break

    return all_data

def save_to_excel(data, filename="dependency_track.xlsx"):
    """Save API response to an Excel file."""
    if not data:
        print("No data to save.")
        return
    
    df = pd.json_normalize(data)  # Flatten nested JSON if needed
    df.to_excel(filename, index=False)
    print(f"Data successfully saved to {filename}")

if __name__ == "__main__":
    data = fetch_all_dependency_data()
    save_to_excel(data)