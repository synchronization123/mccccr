import requests
import pandas as pd
import os

# API details
API_URL = "https://dependencytrackapi.crm.com/api/v1/project"
FINDINGS_API_URL = "https://dependencytrackapi.crm.com/api/v1/finding/project"
API_TOKEN = "bzbdbdhdhd"
HEADERS = {
    "X-Api-Key": API_TOKEN,
    "Content-Type": "application/json",
    "Accept": "application/json"
}

def fetch_all_dependency_data():
    """Fetch all pages of Dependency Track API data."""
    all_data = []
    page = 1
    limit = 100  # Number of records per request

    while True:
        params = {"page": page, "limit": limit}  # Pagination parameters
        try:
            response = requests.get(API_URL, headers=HEADERS, params=params)
            response.raise_for_status()
            data = response.json()

            if not data:
                break  # Stop if no more records
            
            all_data.extend(data)  # Append current batch to full list

            print(f"Fetched {len(data)} records from page {page}")

            # Stop if fewer than 'limit' records are returned (last page)
            if len(data) < limit:
                break

            page += 1  # Move to next page
        except requests.exceptions.RequestException as e:
            print(f"Error fetching data: {e}")
            break

    return all_data

def fetch_findings_for_uuid(uuid, project_name):
    """Fetch findings for a specific UUID."""
    url = f"{FINDINGS_API_URL}/{uuid}"
    try:
        response = requests.get(url, headers=HEADERS)
        response.raise_for_status()
        data = response.json()

        # If no data found, create a blank Excel with headers
        if not data:
            print(f"No findings for UUID: {uuid}. Saving blank Excel.")
            df = pd.DataFrame(columns=["Finding", "Severity", "Description", "analysis.state"])  # Example headers
            df.to_excel(f"{project_name}.xlsx", index=False)
            print(f"Blank Excel file created for UUID: {uuid} with name {project_name}.xlsx")
            return "Analysis Pending"
        else:
            # Convert findings data to a DataFrame and save to Excel
            df = pd.json_normalize(data)
            df.to_excel(f"{project_name}.xlsx", index=False)
            print(f"Data successfully saved for UUID: {uuid} with name {project_name}.xlsx")

            # Check if 'analysis.state' column exists, else return "Analysis Pending"
            return df.get('analysis.state', ['Analysis Pending']).iloc[0]  # Default to "Analysis Pending"

    except requests.exceptions.RequestException as e:
        print(f"Error fetching findings for UUID {uuid}: {e}")
        return "Analysis Pending"

def main():
    # Fetch all projects to get UUIDs
    all_projects = fetch_all_dependency_data()

    # Filter projects where version is 'develop'
    filtered_projects = [project for project in all_projects if project.get('version') == 'develop']

    print(f"Found {len(filtered_projects)} projects with version 'develop'.")

    # Prepare list to store final data for Count.xlsx
    final_data = []

    # For each filtered project, fetch findings using UUID
    for project in filtered_projects:
        uuid = project.get('uuid')
        project_name = project.get('name')  # Get project name to use as filename
        if uuid and project_name:
            analysis_state = fetch_findings_for_uuid(uuid, project_name)
            # Append filename (without extension) and analysis.state
            final_data.append({"Filename": project_name, "analysis.state": analysis_state})
        else:
            print(f"UUID or Name not found for project: {project}")

    # Save the final data into Count.xlsx
    final_df = pd.DataFrame(final_data)
    final_df.to_excel("Count.xlsx", index=False)
    print("Count.xlsx has been successfully created with filenames and analysis state.")

if __name__ == "__main__":
    main()