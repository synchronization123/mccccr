import os
import shutil
import pandas as pd
from datetime import datetime

# Get today's date in required format
today_date = datetime.today().strftime("%d-%b-%Y")  # Example: 27-Jan-2025
file_date = datetime.today().strftime("%Y-%m-%d")   # Example: 2025-01-27

# Define paths
backup_folder = f"backup/{today_date}"
output_folder = f"output/{today_date}"

# Create date-wise directories if not exist
os.makedirs(backup_folder, exist_ok=True)
os.makedirs(output_folder, exist_ok=True)

# Step 1: Move Existing Excel Files to Backup Before Processing
files = [f for f in os.listdir() if f.endswith(".xlsx") and not f.startswith("~$")]

for file in files:
    src_path = os.path.join(file)
    dest_path = os.path.join(backup_folder, file)

    # If file exists in backup, replace it
    if os.path.exists(dest_path):
        os.remove(dest_path)  # Delete old version in backup

    shutil.move(src_path, dest_path)  # Move file to backup

print(f"‚úÖ Moved {len(files)} files to backup folder: {backup_folder}")

# Step 2: Merge All Excel Files from Backup
backup_files = [os.path.join(backup_folder, f) for f in os.listdir(backup_folder) if f.endswith(".xlsx")]
df_list = [pd.read_excel(f, dtype=str) for f in backup_files]
merged_df = pd.concat(df_list, ignore_index=True)

# Save Merged File
merged_file = os.path.join(output_folder, "merged.xlsx")
merged_df.to_excel(merged_file, index=False)

# Ensure required columns exist
required_columns = ["Date", "Issue Key", "Issue Type", "Version", "Assigned To", "Status"]
for col in required_columns:
    if col not in merged_df.columns:
        merged_df[col] = ""

# Step 3: Concatenate Issue Type & Security, then clean up Issue Types
merged_df["Issue Types"] = merged_df["Issue Type"].fillna("") + " " + merged_df["Security"].fillna("")
merged_df["Issue Types"] = merged_df["Issue Types"].str.strip()

# Rename issue types
merged_df["Issue Types"] = merged_df["Issue Types"].replace({
    "Bug Security": "Security",
    "Improvement-Technical Security": "Security",
    "Bug": "Functional bug",
    "Story": "Epic story"
})

# Drop old columns
merged_df.drop(columns=["Issue Type", "Security"], inplace=True)

# Save Concatenated File
concatenated_file = os.path.join(output_folder, "concatenated.xlsx")
merged_df.to_excel(concatenated_file, index=False)

# Step 4: Display Summary by Issue Type
issue_type_summary = merged_df.groupby("Issue Types")["Issue Key"].count().reset_index()
issue_type_summary.columns = ["Issue Type", "Total Issues"]
print("\nüìå Summary by Issue Type:")
print(issue_type_summary.to_string(index=False))

# Step 5: Get User Input for Assignment
user_assignments = {}
for issue_type, count in issue_type_summary.values:
    required_users = (count + 29) // 30
    print(f"\nFor issue type '{issue_type}', we need around {required_users} user(s) for {count} issues.")
    users_input = input(f"Enter comma-separated users for issue type '{issue_type}' (up to {required_users} users): ")
    users = [u.strip() for u in users_input.split(",") if u.strip()]

    if not users:
        print(f"‚ö†Ô∏è Warning: No users entered for '{issue_type}'. These issues will remain unassigned.")
    
    user_assignments[issue_type] = users

# Step 6: Assign Issues Sequentially
merged_df["Assigned To"] = ""

for issue_type, users in user_assignments.items():
    if not users:
        continue  # Skip if no users entered for this issue type

    issue_mask = merged_df["Issue Types"] == issue_type
    issue_indices = merged_df[issue_mask].index
    num_issues = len(issue_indices)
    
    # Determine issues per user
    num_users = len(users)
    issues_per_user = (num_issues + num_users - 1) // num_users  

    # Assign sequentially
    assigned_users = []
    user_index = 0

    for i, idx in enumerate(issue_indices):
        assigned_users.append(users[user_index])
        if (i + 1) % issues_per_user == 0 and user_index < num_users - 1:
            user_index += 1

    merged_df.loc[issue_indices, "Assigned To"] = assigned_users

# Step 7: Split into Develop & Non-Develop
merged_df["Version"] = merged_df["Version"].fillna("")
develop_df = merged_df[merged_df["Version"].str.contains("develop", case=False, na=False)].copy()
non_develop_df = merged_df[~merged_df["Version"].str.contains("develop", case=False, na=False)].copy()

# Remove blank Version rows from non-develop
non_develop_df = non_develop_df[non_develop_df["Version"].str.strip() != ""]

# Arrange Columns
column_order = ["Date", "Issue Key", "Issue Types", "Version", "Assigned To", "Status"]
develop_df = develop_df[column_order]
non_develop_df = non_develop_df[column_order]

# Fill missing dates
develop_df["Date"] = today_date
develop_df["Assigned On"] = today_date
non_develop_df["Date"] = today_date
non_develop_df["Assigned On"] = today_date

# Step 8: Save Final Files
develop_file = os.path.join(output_folder, f"Develop_jiras_{file_date}.xlsx")
non_develop_file = os.path.join(output_folder, f"Non_Develop_jiras_{file_date}.xlsx")

develop_df.to_excel(develop_file, index=False)
non_develop_df.to_excel(non_develop_file, index=False)

# Step 9: Cleanup - Delete Intermediate Files
os.remove(merged_file)
os.remove(concatenated_file)

# Step 10: Display Summary by Version and Assigned To
print("\nüìå Summary by Version (Grouped by Issue Type):")
version_summary = merged_df.groupby(['Version', 'Issue Types'])["Issue Key"].count().reset_index()
version_summary.columns = ["Version", "Issue Type", "Total Issues"]
print(version_summary.to_string(index=False))

print("\nüìå Summary by Assigned To:")
assigned_to_summary = merged_df.groupby("Assigned To")["Issue Key"].count().reset_index()
assigned_to_summary.columns = ["Assigned To", "Total Issues"]
print(assigned_to_summary.to_string(index=False))

print("\n‚úÖ Processing complete. Files saved:")
print(f"- {develop_file}")
print(f"- {non_develop_file}")
print(f"- Backup files stored in '{backup_folder}'")